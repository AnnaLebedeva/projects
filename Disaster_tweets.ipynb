{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c89ec67",
   "metadata": {},
   "source": [
    "Код к соревнованию https://www.kaggle.com/competitions/nlp-getting-started/  \n",
    "Задача - научить модель распознавать твиты, в которых есть информация о природных катаклизмах, а в каких нет. Датасет состоит из 10000 твитов, размеченных вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6255de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from string import punctuation\n",
    "punctuation += \"«»—…“”\"\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1047db5",
   "metadata": {},
   "source": [
    "Импортируем датасеты чтобы обучать модель и проверять качество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03add415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5) (3263, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded4a63",
   "metadata": {},
   "source": [
    "Посмотрим на примеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88c92cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love fruits'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# нейтральный твит\n",
    "train_df[train_df[\"target\"] == 0][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16726f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# твит про катаклизм\n",
    "train_df[train_df[\"target\"] == 1][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddfbe9d",
   "metadata": {},
   "source": [
    "Проведём предобработку текстов: уберём пунктуацию и приведём слова к первоначальной форме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be34bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer # класс лемматизатор\n",
    "from nltk.corpus import wordnet # WordNet — это лексическая база данных английского языка\n",
    "from nltk.tokenize import word_tokenize # разделяет предложение по пробелам, на выходе список\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9707ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b49974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вспомогательная функция для лемматизатора\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc6fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    return ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)).lower() for w in nltk.word_tokenize(sentence)\\\n",
    "            if w not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400571b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделать векторы с предобработанными твитами\n",
    "preprocessed_train = [preprocess(sentence) for sentence in train_df[\"text\"]]\n",
    "preprocessed_test = [preprocess(sentence) for sentence in test_df[\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d799c",
   "metadata": {},
   "source": [
    "Векторизуем тексты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e932db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b01f7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = tfidf_vectorizer.fit_transform(pd.Series(preprocessed_train))\n",
    "                                              \n",
    "## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n",
    "# that the tokens in the train vectors are the only ones mapped to the test vectors - \n",
    "# i.e. that the train and test vectors use the same set of tokens.\n",
    "test_vectors = tfidf_vectorizer.transform(pd.Series(preprocessed_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234396a",
   "metadata": {},
   "source": [
    "Инициализируем классификатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "401a8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Our vectors are really big, so we want to push our model's weights\n",
    "## toward 0 without completely discounting different words - ridge regression \n",
    "## is a good way to do this.\n",
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba92457",
   "metadata": {},
   "source": [
    "Проверяем качество полученной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "750cf490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6401742 , 0.61984733, 0.67342799])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b08765b",
   "metadata": {},
   "source": [
    "Я пробовала ещё два классификатора, но они показали результаты хуже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cdcc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# clf = BaggingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2129af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daf70b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7359e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "# scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ac393",
   "metadata": {},
   "source": [
    "Подготавливаем файл для соревнования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ea32a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_vectors, train_df[\"target\"])\n",
    "# X{ndarray, sparse matrix} of shape (n_samples, n_features)\n",
    "# Training data.\n",
    "\n",
    "# yndarray of shape (n_samples,)\n",
    "# Target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6806723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db53ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"target\"] = clf.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14c7bb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02aae1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ec5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
