{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задача построения модели подбора рекомендаций фильмов\n",
        "\n",
        "В данном ноутбуке решается задача построения рекомендательной системы, которая на основе построения эмбедингов пользователей и эмбедингов фильмов могла бы рекомендовать наиболее релевантные новые фильмы пользователям.\n",
        "\n",
        "Я буду решать эту задачу при помощи pyspark - фреймворка для распределенной обработки больших данных."
      ],
      "metadata": {
        "id": "gEw-5tkDBs7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Установка необходимых фреймворков и загрузка данных"
      ],
      "metadata": {
        "id": "RogkERGQFiAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Java JDK\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Downloading Spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n",
        "#Unzipping the hadoop file\n",
        "!tar -xvf spark-3.4.0-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "VIxRFR8Q1y2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# скачиваем датасет\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-latest.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGZWNY6Q1ymH",
        "outputId": "6a5ffb38-d89d-468c-dd71-0a74334b7fef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-10 20:31:39--  http://files.grouplens.org/datasets/movielens/ml-latest.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 277113433 (264M) [application/zip]\n",
            "Saving to: ‘ml-latest.zip’\n",
            "\n",
            "ml-latest.zip       100%[===================>] 264.28M  53.0MB/s    in 5.3s    \n",
            "\n",
            "2023-05-10 20:31:45 (50.0 MB/s) - ‘ml-latest.zip’ saved [277113433/277113433]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# разархивируем\n",
        "!unzip ml-latest.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzlQG0jR1yz5",
        "outputId": "389451f1-5f0b-40ff-e1cf-b08b0f79a68f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ml-latest.zip\n",
            "   creating: ml-latest/\n",
            "  inflating: ml-latest/links.csv     \n",
            "  inflating: ml-latest/tags.csv      \n",
            "  inflating: ml-latest/genome-tags.csv  \n",
            "  inflating: ml-latest/ratings.csv   \n",
            "  inflating: ml-latest/README.txt    \n",
            "  inflating: ml-latest/genome-scores.csv  \n",
            "  inflating: ml-latest/movies.csv    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# устанавливаем findspark\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "UHmMu5Yf10YX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\""
      ],
      "metadata": {
        "id": "bieGdlTe1235"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# инициализируем сессию\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "UphniWKw14jO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# задаем путь к файлам\n",
        "ratings_file ='/content/ml-latest/ratings.csv'\n",
        "movies_file = '/content/ml-latest/movies.csv'\n",
        "links_file = '/content/ml-latest/links.csv'"
      ],
      "metadata": {
        "id": "FUY9LLus227y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readFiles(filename):\n",
        "  data = spark.read.format('com.databricks.spark.csv').\\\n",
        "                               options(header='true', \\\n",
        "                               inferschema='true').\\\n",
        "                load(filename,header=True)\n",
        "  return data"
      ],
      "metadata": {
        "id": "QP-5orlC16o_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# считываем данные\n",
        "ratings = readFiles(ratings_file)\n",
        "movies = readFiles(movies_file)\n",
        "links = readFiles(links_file)"
      ],
      "metadata": {
        "id": "vZIADsXJ23nW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkNa6Qa_26GK",
        "outputId": "4abd3c12-f00e-4622-c00f-bab2b5675110"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    307|   3.5|1256677221|\n",
            "|     1|    481|   3.5|1256677456|\n",
            "|     1|   1091|   1.5|1256677471|\n",
            "|     1|   1257|   4.5|1256677460|\n",
            "|     1|   1449|   4.5|1256677264|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подготовка данных для обучения, разбиение"
      ],
      "metadata": {
        "id": "yv7cTVBbF1i5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Минимальный набор данных для построения рекомендательной системы - таблица взаимодействий (интеракций) пользователь-контент. Система логирования пользовательских действий сохраняет:\n",
        "- пару пользователь-контент\n",
        "- меру взаимодействия (например, рейтинг)\n",
        "- временную метку, когда произошла интеракция.\n",
        "\n",
        "Рекомендательные системы строятся вокруг этой таблицы. Такие данные можно представить в виде т.н. матрицы user-item matrix, где каждая строка - это пользователь, каждый столбец - контент. А в пересечении строки и столбца находится мера взаимодействия (в данном случае рейтинг). Для обучения модели нам понадобятся только эти данные: id пользователей и фильмов и рейтинги. Поэтому за основу мы возьмем таблицу ratings и удалим из неё столбец timestamp.\n",
        "\n",
        "Матрица будет разреженной."
      ],
      "metadata": {
        "id": "XG6upg0HGL02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = ratings.drop(\"timestamp\")"
      ],
      "metadata": {
        "id": "wirFH-ef5jyW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разбиваем данные на train и test в пропорции 80/20. Это часто встречающаяся пропорция для разделения. Такой выбор основывается на мысли о том, что отсутствие достаточного количества данных как в обучающем, так и в проверочном наборе приведет к тому, что модель будет трудно изучить/обучить или определить, действительно ли эта модель работает хорошо или нет."
      ],
      "metadata": {
        "id": "ph790yLiICuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = data.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "FEAklX2N5j0t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метод и обоснование"
      ],
      "metadata": {
        "id": "Cm9DKVB9QIt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Таблица взаимодействий пользователь-контент представляет собой матрицу, а к матрице можно применить алгоритмы матричной факторизации. После этого\n",
        "с помощью матричного разложения мы получаем две матрицы более низкой размерности - одна описывает пользователей (факторы пользователей), вторая контент (факторы контента).\n",
        "Чтобы получить рекомендации нужно вектор факторов пользователя (соответствующую строку в матрице) умножить на факторы контента и отсортировать полученные значения. Для матричного разложения можно использовать SVD или более продвинутый метод ALS-разложения. Мы используем второй метод, реализованный в pyspark."
      ],
      "metadata": {
        "id": "0HJUOTyhJxyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS"
      ],
      "metadata": {
        "id": "ZPPj84H-5j3H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# инициализируем параметры модели и обучаем её:\n",
        "# nonnegative отвечает за необходимость получения неотрицательных значений в результате обучения. По умолчанию False.\n",
        "# True применяется, когда переменные в физическом смысле не могут быть отрицательными, как рейтинг в нашем случае.\n",
        "# coldStartStrategy = “drop” применяется чтобы игнорировать строки df где предсказания содержат NaN\n",
        "model = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative=True, coldStartStrategy=\"drop\").fit(train)"
      ],
      "metadata": {
        "id": "MeIpAwnZ5j5h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метрика и обоснование"
      ],
      "metadata": {
        "id": "jEF2SLkTQtEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качество рекомендательной модели можно измерить как метриками классификации, так и метриками регрессии. При обучении ALS мы оптимизируем метрику, которая “приближает” произведение матриц факторов пользователей и контента к исходной матрице. В такой постановке можно использовать классические метрике RMSE, MAE для определения того, насколько хорошо “угадываем” уже существующие оценки. Также можно использовать метрики Precision и Recall.\n",
        "Recall – доля релевантных объектов, показанных пользователю, относительно всех релевантных объектов.\n",
        "Precision – доля релевантных пользователю объектов относительно тех, которые ему показали.\n",
        "Я буду использовать RMSE."
      ],
      "metadata": {
        "id": "2Y4dvclcP2pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# инициализируем RegressionEvaluator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")"
      ],
      "metadata": {
        "id": "c_FUHOcVP173"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# вычисляем предсказания и считаем RMSE на тестовой выборке\n",
        "predictions=model.transform(test)\n",
        "rmse=evaluator.evaluate(predictions)\n",
        "print(\"New RMSE: \", evaluator.evaluate(model.transform(test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrZWCBXj5kFB",
        "outputId": "47e0afb3-15c0-427e-d97b-19893d449aed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New RMSE:  0.8247412247250272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# пример рекомендаций:\n",
        "for_an_user = predictions.where(predictions.userId==234926).join(movies, \"movieId\").join(links, \"movieId\").select(\"userId\",\"title\",\"tmdbId\",\"genres\",\"prediction\")\n",
        "for_an_user.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoKdv1JcbBtL",
        "outputId": "06840743-4c5f-458a-b6cf-d886081b0145"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+------+--------------------+----------+\n",
            "|userId|               title|tmdbId|              genres|prediction|\n",
            "+------+--------------------+------+--------------------+----------+\n",
            "|234926|    Assassins (1995)|  9691|Action|Crime|Thri...|  2.581965|\n",
            "|234926|Seven (a.k.a. Se7...|   807|    Mystery|Thriller|  3.585339|\n",
            "|234926|    City Hall (1996)| 11062|      Drama|Thriller| 3.0170746|\n",
            "|234926|Awfully Big Adven...| 22279|               Drama| 2.8612847|\n",
            "|234926|        Congo (1995)| 10329|Action|Adventure|...| 2.1707146|\n",
            "+------+--------------------+------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmlVI6zdbJzC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}